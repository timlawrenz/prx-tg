# Production Training Configuration
# Based on the-plan.md Part D specifications

model:
  hidden_size: 768             # Hidden dimension (scale to 768-1024 for production)
  depth: 18                    # Number of transformer layers (start small, scale to 24-28)
  num_heads: 12                 # Attention heads
  patch_size: 2                # Spatial downsampling (2 for high detail as per plan)
  mlp_ratio: 4.0               # MLP expansion factor
  in_channels: 16              # VAE latent channels
  input_size: 128              # Validation/sampling latent size (1024px / 8 = 128)

training:
  total_steps: 6000           # Total optimizer steps (approx 14 days on 4090)
  warmup_steps: 500           # Linear LR warmup
  batch_size: 1               # Per-GPU batch size
  grad_accumulation_steps: 256 # Effective batch
  
  optimizer:
    type: "AdamW"
    lr: 3.0e-4                 # Peak learning rate (from-scratch training)
    min_lr: 1.0e-6             # Minimum LR after cosine decay
    betas: [0.9, 0.95]         # Beta values (0.95 faster than standard 0.999)
    weight_decay: 0.03         # Standard regularization
    eps: 1.0e-8
  
  grad_clip: 1.0               # Gradient clipping norm
  ema_decay: 0.9999            # Target EMA decay
  ema_warmup_steps: 500       # Warm EMA from 0 to target over N steps
  
  # CFG dropout (mutually exclusive categorical as per fixed validation code)
  cfg_dropout:
    p_uncond: 0.1              # Drop both DINO and text (unconditional)
    p_text_only: 0.3           # Drop DINO more often (reduce DINO reliance)
    p_dino_only: 0.05          # Drop text less often (reduce DINO-only cases)
    # Remaining 55% keeps both signals

  # Timestep sampling strategy
  timestep_sampling: "logit_normal"  # "uniform" or "logit_normal"
  logit_normal_loc: 0.0              # Mean of logit-normal distribution
  logit_normal_scale: 1.0            # Std of logit-normal distribution
  
  # Memory optimization
  gradient_checkpointing: true       # Enable to trade 20-30% speed for 3-4x memory savings
  
  # Precision
  mixed_precision: true              # Use bfloat16 (required for flow matching)
  precision: "bfloat16"              # "bfloat16" or "float32"

data:
  shard_base_dir: "data/shards/15000"      # Base directory for WebDataset shards
  
  # Aspect ratio buckets to read (each bucket is a subdirectory with tar files)
  buckets:
    - "bucket_1024x1024"
    - "bucket_1216x832"
    - "bucket_1280x768"
    - "bucket_1344x704"
    - "bucket_704x1344"
    - "bucket_768x1280"
    - "bucket_832x1216"
  
  # Bucket sampling strategy (for bucket-aware batching)
  bucket_sampling: "proportional"    # "proportional" or "uniform"

  # Augmentation
  horizontal_flip_prob: 0.5          # Flip probability
  # NOTE: Caption swapping (leftâ†”right) is NOT supported because T5 embeddings
  # are pre-computed. Caption text is unused during training (only T5 embeddings matter).
  
  # DataLoader settings
  num_workers: 4                     # Parallel workers
  prefetch_factor: 2                 # Batches to prefetch per worker
  pin_memory: true                   # Pin memory for faster GPU transfer

sampling:
  num_steps: 25                      # Euler integration steps
  text_scale: 3.0                    # CFG scale for text conditioning
  dino_scale: 2.5                    # CFG scale for DINO conditioning

validation:
  enabled: true                      # Enable validation runs
  interval_steps: 500               # Run validation every N steps (full suite)
  num_samples: 25                    # Number of samples to validate
  output_dir: "validation_outputs"   # Validation output directory
  
  # Validation tests to run
  run_reconstruction: true           # Test reconstruction LPIPS
  run_dino_swap: true                # Test DINO swap pairs
  run_text_manip: true               # Test text manipulation
  
  # Visual debugging (quick image generation during training)
  visual_debug_interval: 100        # Generate sample images every N steps (0 = disabled)
  visual_debug_num_samples: 4        # Number of samples per visual debug checkpoint
  visual_debug_dir: "visual_debug"   # Output directory for visual debugging images

checkpoint:
  save_every: 500                   # Save checkpoint every N steps
  keep_last_n: 3                     # Keep only last N checkpoints (0 = keep all)
  output_dir: "checkpoints"          # Checkpoint output directory
  save_optimizer: true               # Save optimizer state (needed for resume)

logging:
  log_every: 5                      # Log metrics every N steps
  log_file: "training.log"           # JSON-lines log file
  
  # Monitoring (from the-plan.md Part E)
  monitor_velocity_norm: true        # Track |v_pred| magnitude
  monitor_grad_norm: true            # Track gradient norm
  velocity_norm_warning: 10.0        # Warn if |v_pred| > this (collapse detection)
  grad_norm_warning: 10.0            # Warn if grad_norm > this after warmup

# Paths (relative to project root)
paths:
  vae_path: "models/vae.safetensors"         # Flux VAE checkpoint
  t5_path: "models/t5xxl_fp16.safetensors"   # T5-XXL encoder (for validation)
